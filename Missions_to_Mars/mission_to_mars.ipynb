{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pymongo\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Set up Splinter\n",
    "#     executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "#     executable_path = {'executable_path': 'chromedriver'}\n",
    "#     browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "   # Scrape page into Soup\n",
    "#     def scrape():\n",
    "        executable_path = {'executable_path': 'chromedriver'}\n",
    "        browser = Browser('chrome', **executable_path, headless=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "db = client.commerce_db\n",
    "collection = db.items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### NASA Mars News\n",
    "\n",
    "# * Scrape the [Mars News Site](https://redplanetscience.com/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later.\n",
    "\n",
    "# ```python\n",
    "# # Example:\n",
    "# news_title = \"NASA's Next Mars Mission to Investigate Interior of Red Planet\"\n",
    "\n",
    "# news_p = \"Preparation of NASA's next spacecraft to Mars, InSight, has ramped up this summer, on course for launch next May from Vandenberg Air Force Base in central California -- the first interplanetary launch in history from America's West Coast.\"\n",
    "# ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mars_news(): \n",
    "        \n",
    "        url = \"https://redplanetscience.com/\"\n",
    "        browser.visit(url)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "        html = browser.html\n",
    "        soup = bs(html, \"html.parser\")\n",
    "    \n",
    "        mars_title = soup.find('div', class_ = 'content_title').get_text()\n",
    "        mars_paragraph = soup.find('div', class_ = 'article_teaser_body').get_text()\n",
    "    \n",
    "        #     print(f\"{mars_title}\")\n",
    "        mars_title\n",
    "        mars_paragraph\n",
    "\n",
    "        mars_results = [mars_title, mars_paragraph]\n",
    "        mars_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ### JPL Mars Space Images - Featured Image\n",
    "\n",
    "# * Visit the url for the Featured Space Image site [here](https://spaceimages-mars.com).\n",
    "\n",
    "# * Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "# * Make sure to find the image url to the full size `.jpg` image.\n",
    "\n",
    "# * Make sure to save a complete url string for this image.\n",
    "\n",
    "# ```python\n",
    "# # Example:\n",
    "# featured_image_url = 'https://spaceimages-mars.com/image/featured/mars2.jpg'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# grab our new html from surfline      ******   FROM webscrape 3  extra content\n",
    "\n",
    "#     browser.is_element_present_by_css(\".sl-premium-analysis-link\", 1)\n",
    "#     analysis_url = browser.find_link_by_partial_href(\"premium-analysis\").first[\"href\"]\n",
    "#     browser.visit(analysis_url)\n",
    "#     browser.is_element_present_by_css(\".sl-feed-article\", 1)\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mars_image():\n",
    "url = \"https://spaceimages-mars.com/\"\n",
    "browser.visit(url)\n",
    "time.sleep(2)\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "image = soup.find(\"img\", class_=\"headerimage fade-in\").get(\"src\")\n",
    "                            \n",
    "# image \n",
    "featured_image_url= \"https://spaceimages-mars.com\" + image\n",
    "    \n",
    "print(f\"url: {featured_image_url}\")\n",
    "#     return featured_image_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Mars Facts\n",
    "\n",
    "# * Visit the Mars Facts webpage [here](https://galaxyfacts-mars.com) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "# * Use Pandas to convert the data to a HTML table string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marsfacts_url = \"https://galaxyfacts-mars.com\"\n",
    "\n",
    "htm = pd.read_html(marsfacts_url)\n",
    "mars_tables_df = htm[0]\n",
    "mars_tables_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    marsfacts_url = 'https://galaxyfacts-mars.com'\n",
    "\n",
    "    marsfacts= pd.read_html(marsfacts_url)[0]\n",
    "    \n",
    "    \n",
    "    marsfacts.columns = ['Description', 'Mars', 'Earth']\n",
    "    marsfacts.set_index('Description', inplace=True)\n",
    "    marsfacts_html = marsfacts.to_html()\n",
    "    marsfacts_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    clean_html = marsfacts_html.replace('\\n', '')\n",
    "    clean_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_html = mars_tables_df.to_html('marsfacts_html')\n",
    "mars_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Mars Hemispheres\n",
    "\n",
    "# * Visit the astrogeology site [here](https://marshemispheres.com/) to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "# * You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "# * Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "\n",
    "# * Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n",
    "\n",
    "# ```python\n",
    "# # Example:\n",
    "# hemisphere_image_urls = [\n",
    "#     {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"# Schiaparelli\n",
    "\n",
    "\n",
    "url = 'https://marshemispheres.com/'\n",
    "browser.visit(url)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "browser.links.find_by_partial_text('Schiaparelli').click()\n",
    "\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html,\"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "img_link = soup.find('img', class_='wide-image').get('src')\n",
    "\n",
    "\n",
    "planet_dict = []\n",
    "\n",
    "url = 'https://marshemispheres.com/'\n",
    "browser.visit(url)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "browser.links.find_by_partial_text('Cerberus').click()\n",
    "\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html,\"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "img_link = soup.find('img', class_='wide-image').get('src')\n",
    " \n",
    "cerberus_title = soup.find('h2', class_='title').text\n",
    "\n",
    "\n",
    "\n",
    "cerberus_img = url + img_link\n",
    "\n",
    "\n",
    "browser.back()\n",
    "\n",
    "\n",
    "cerberus_dict = {'title:' + cerberus_title, 'img_url:' + cerberus_img}\n",
    "planet_dict.append(cerberus_dict)\n",
    "\n",
    "cerberus_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_url:https://marshemispheres.com/images/3778f7b43bbbc89d6e3cfabb3613ba93_schiaparelli_enhanced.tif_full.jpg',\n",
       " 'title:Schiaparelli Hemisphere Enhanced'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Schiaparelli\n",
    "\n",
    "\n",
    "url = 'https://marshemispheres.com/'\n",
    "browser.visit(url)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "browser.links.find_by_partial_text('Schiaparelli').click()\n",
    "\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html,\"html.parser\")\n",
    "\n",
    "img_link = soup.find('img', class_='wide-image').get('src')\n",
    "\n",
    "\n",
    "schiaparelli_title = soup.find('h2', class_='title').text\n",
    "\n",
    "\n",
    "\n",
    "schiaparelli_img = url + img_link\n",
    "\n",
    "\n",
    "browser.back()\n",
    "\n",
    "\n",
    "schiaparelli_dict = {'title:' + schiaparelli_title, 'img_url:' + schiaparelli_img}\n",
    "planet_dict.append(schiaparelli_dict)\n",
    "\n",
    "schiaparelli_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_url:https://marshemispheres.com/images/555e6403a6ddd7ba16ddb0e471cadcf7_syrtis_major_enhanced.tif_full.jpg',\n",
       " 'title:Syrtis Major Hemisphere Enhanced'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Syrtis\n",
    "\n",
    "\n",
    "url = 'https://marshemispheres.com/'\n",
    "browser.visit(url)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "browser.links.find_by_partial_text('Syrtis').click()\n",
    "\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html,\"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "img_link = soup.find('img', class_='wide-image').get('src')\n",
    "\n",
    "\n",
    "syrtis_title = soup.find('h2', class_='title').text\n",
    "\n",
    "\n",
    "\n",
    "syrtis_img = url + img_link\n",
    "\n",
    "\n",
    "browser.back()\n",
    "\n",
    "\n",
    "syrtis_dict = {'title:' + syrtis_title, 'img_url:' + syrtis_img}\n",
    "planet_dict.append(syrtis_dict)\n",
    "\n",
    "syrtis_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valles Marineris\n",
    "\n",
    "\n",
    "url = 'https://marshemispheres.com/'\n",
    "browser.visit(url)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "browser.links.find_by_partial_text('Valles Marineris').click()\n",
    "\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html,\"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "img_link = soup.find('img', class_='wide-image').get('src')\n",
    "\n",
    "\n",
    "valles_title = soup.find('h2', class_='title').text\n",
    "\n",
    "\n",
    "\n",
    "valles_img = url + img_link\n",
    "\n",
    "\n",
    "browser.back()\n",
    " \n",
    "\n",
    "valles_dict = {'title:' + valles_title, 'img_url:' + valles_img}\n",
    "planet_dict.append(valles_dict)\n",
    "\n",
    "valles_dict\n",
    "\n",
    "\n",
    "planet_dict\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Step 1 - Scraping\n",
    "\n",
    "# Complete your initial scraping using Jupyter Notebook, BeautifulSoup, Pandas, and Requests/Splinter.\n",
    "\n",
    "# * Create a Jupyter Notebook file called `mission_to_mars.ipynb` and use this to complete all of your scraping and analysis tasks. The following outlines what you need to scrape.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ### NASA Mars News\n",
    "\n",
    "# * Scrape the [Mars News Site](https://redplanetscience.com/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later.\n",
    "\n",
    "# ```python\n",
    "# # Example:\n",
    "# news_title = \"NASA's Next Mars Mission to Investigate Interior of Red Planet\"\n",
    "\n",
    "# news_p = \"Preparation of NASA's next spacecraft to Mars, InSight, has ramped up this summer, on course for launch next May from Vandenberg Air Force Base in central California -- the first interplanetary launch in history from America's West Coast.\"\n",
    "# ```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ### JPL Mars Space Images - Featured Image\n",
    "\n",
    "# * Visit the url for the Featured Space Image site [here](https://spaceimages-mars.com).\n",
    "\n",
    "# * Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "# * Make sure to find the image url to the full size `.jpg` image.\n",
    "\n",
    "# * Make sure to save a complete url string for this image.\n",
    "\n",
    "# ```python\n",
    "# # Example:\n",
    "# featured_image_url = 'https://spaceimages-mars.com/image/featured/mars2.jpg'\n",
    "# ```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ### Mars Facts\n",
    "\n",
    "# * Visit the Mars Facts webpage [here](https://galaxyfacts-mars.com) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "# * Use Pandas to convert the data to a HTML table string.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ### Mars Hemispheres\n",
    "\n",
    "# * Visit the astrogeology site [here](https://marshemispheres.com/) to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "# * You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "# * Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "\n",
    "# * Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n",
    "\n",
    "# ```python\n",
    "# # Example:\n",
    "# hemisphere_image_urls = [\n",
    "#     {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "# ]\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
